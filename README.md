# Clusteriza√ß√£o de Vinhos com PCA e K-Means

### Objetivo

O objetivo deste projeto √© agrupar diferentes tipos de vinhos em clusters com base em suas caracter√≠sticas qu√≠micas.
Utilizamos o PCA (An√°lise de Componentes Principais) para reduzir o n√∫mero de vari√°veis e o K-Means para identificar grupos (clusters) de vinhos semelhantes.

### Dataset

Foi utilizado o Wine Dataset do Scikit-learn, que cont√©m:
- 178 amostras de vinhos;
- 13 vari√°veis qu√≠micas (como teor alco√≥lico, magn√©sio, fen√≥is, cor, etc.);
- 3 classes reais, representando vinhos de tr√™s produtores diferentes.

### Entendendo o Problema

Imagine que recebemos dados qu√≠micos de v√°rios vinhos, mas sem saber de qual produtor eles vieram.
A tarefa √© agrupar os vinhos que s√£o quimicamente parecidos, formando grupos com base nas semelhan√ßas dos atributos.

### Por que usar PCA?

O dataset tem 13 dimens√µes, o que dificulta a visualiza√ß√£o.
O PCA reduz essas dimens√µes para 2 componentes principais, mantendo a maior parte da informa√ß√£o dos dados.
Isso nos permite plotar os vinhos em um gr√°fico 2D e visualizar como se agrupam naturalmente.

### Por que usar K-Means?

Depois da redu√ß√£o com o PCA, aplicamos o K-Means, um algoritmo de clusteriza√ß√£o que agrupa os pontos pr√≥ximos uns dos outros.
Como sabemos que h√° 3 tipos de vinho, definimos k = 3.

### O C√≥digo

O c√≥digo segue a seguinte estrutura:
- Carrega o dataset Wine do Scikit-learn.
- Escala os dados (o PCA √© sens√≠vel √† escala).
- Reduz as dimens√µes de 13 para 2 com o PCA.
- Aplica o K-Means com 3 clusters.
- Gera gr√°ficos comparando os clusters encontrados com as classes reais.

### Resultados Obtidos

Ap√≥s a execu√ß√£o, dois gr√°ficos foram gerados:

üîπ Clusters Encontrados pelo K-Means

Mostra os grupos criados automaticamente pelo algoritmo com base na similaridade dos vinhos.
Os pontos coloridos representam os clusters e os ‚ÄúX‚Äù vermelhos s√£o os centr√≥ides dos grupos.

üîπ Classes Reais dos Vinhos

Mostra as classes verdadeiras (os tr√™s produtores de vinho) para compara√ß√£o.

### Conclus√£o

Os resultados mostram que o PCA conseguiu separar bem os grupos no espa√ßo bidimensional, e o K-Means identificou clusters muito pr√≥ximos das classes reais.
A vari√¢ncia explicada pelos dois primeiros componentes principais ficou acima de 55%, indicando que a maior parte da estrutura dos dados foi preservada.

Este projeto demonstra como PCA e K-Means podem ser combinados para entender e visualizar padr√µes ocultos em conjuntos de dados complexos, sem a necessidade de r√≥tulos pr√©vios.
